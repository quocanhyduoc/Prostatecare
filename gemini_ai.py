import json
import logging
import os
from datetime import datetime
from google import genai
from google.genai import types

# Initialize Gemini client
client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))

def evaluate_prostate_cancer_risk(patient_data):
    """
    ÄÃ¡nh giÃ¡ nguy cÆ¡ ung thÆ° tuyáº¿n tiá»n liá»‡t báº±ng AI Gemini
    Evaluate prostate cancer risk using AI Gemini
    """
    try:
        # Prepare patient data for AI analysis
        clinical_data = {
            'age': patient_data.get('age'),
            'psa_level': patient_data.get('initial_psa'),
            'gleason_score': patient_data.get('gleason_score'),
            'clinical_t': patient_data.get('clinical_t'),
            'clinical_n': patient_data.get('clinical_n'),
            'clinical_m': patient_data.get('clinical_m'),
            'pathological_t': patient_data.get('pathological_t'),
            'pathological_n': patient_data.get('pathological_n'),
            'pathological_m': patient_data.get('pathological_m'),
            'sampling_method': patient_data.get('sampling_method')
        }

        # Create comprehensive prompt for AI analysis
        prompt = f"""
        Báº¡n lÃ  má»™t chuyÃªn gia ung thÆ° há»c chuyÃªn vá» ung thÆ° tuyáº¿n tiá»n liá»‡t. HÃ£y phÃ¢n tÃ­ch dá»¯ liá»‡u bá»‡nh nhÃ¢n vÃ  Ä‘Æ°a ra Ä‘Ã¡nh giÃ¡ nguy cÆ¡ chi tiáº¿t.

        THÃ”NG TIN Bá»†NH NHÃ‚N:
        - Tuá»•i: {clinical_data['age']} tuá»•i
        - PSA ban Ä‘áº§u: {clinical_data['psa_level']} ng/mL
        - Äiá»ƒm Gleason: {clinical_data['gleason_score']}
        - Giai Ä‘oáº¡n T lÃ¢m sÃ ng: {clinical_data['clinical_t']}
        - Giai Ä‘oáº¡n N lÃ¢m sÃ ng: {clinical_data['clinical_n']}
        - Giai Ä‘oáº¡n M lÃ¢m sÃ ng: {clinical_data['clinical_m']}
        - Giai Ä‘oáº¡n T giáº£i pháº«u bá»‡nh: {clinical_data['pathological_t']}
        - Giai Ä‘oáº¡n N giáº£i pháº«u bá»‡nh: {clinical_data['pathological_n']}
        - Giai Ä‘oáº¡n M giáº£i pháº«u bá»‡nh: {clinical_data['pathological_m']}
        - PhÆ°Æ¡ng phÃ¡p láº¥y máº«u: {clinical_data['sampling_method']}

        YÃŠU Cáº¦U PHÃ‚N TÃCH:
        1. PhÃ¢n táº§ng nguy cÆ¡ theo thang Ä‘iá»ƒm D'Amico (LOW, INTERMEDIATE, HIGH)
        2. ÄÃ¡nh giÃ¡ tiÃªn lÆ°á»£ng sá»‘ng sÃ³t 5 nÄƒm vÃ  10 nÄƒm
        3. Khuyáº¿n nghá»‹ phÆ°Æ¡ng phÃ¡p Ä‘iá»u trá»‹ phÃ¹ há»£p
        4. Äá» xuáº¥t lá»‹ch theo dÃµi vÃ  xÃ©t nghiá»‡m
        5. CÃ¡c yáº¿u tá»‘ nguy cÆ¡ cáº§n lÆ°u Ã½

        HÃ£y tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, ngáº¯n gá»n vÃ  dá»… hiá»ƒu cho nhÃ¢n viÃªn y táº¿.
        Äá»‹nh dáº¡ng káº¿t quáº£ theo JSON vá»›i cÃ¡c trÆ°á»ng: risk_level, survival_5yr, survival_10yr, treatment_recommendation, follow_up_plan, risk_factors.
        """

        # Call Gemini API
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=prompt,
            config=types.GenerateContentConfig(
                response_mime_type="application/json"
            )
        )

        if response.text:
            result = json.loads(response.text)
            
            # Map risk level to standard categories
            risk_mapping = {
                'LOW': 'THáº¤P',
                'INTERMEDIATE': 'TRUNG BÃŒNH', 
                'HIGH': 'CAO',
                'VERY_HIGH': 'Ráº¤T CAO'
            }
            
            # Process and validate the result
            processed_result = {
                'risk_score': result.get('risk_level', 'TRUNG BÃŒNH'),
                'assessment_summary': f"""
ğŸ¯ PHÃ‚N Táº¦NG NGUY CÆ : {risk_mapping.get(result.get('risk_level', 'INTERMEDIATE'), 'TRUNG BÃŒNH')}

ğŸ“Š TIÃŠN LÆ¯á»¢NG Sá»NG SÃ“T:
â€¢ 5 nÄƒm: {result.get('survival_5yr', 'ChÆ°a xÃ¡c Ä‘á»‹nh')}
â€¢ 10 nÄƒm: {result.get('survival_10yr', 'ChÆ°a xÃ¡c Ä‘á»‹nh')}

ğŸ’Š KHUYáº¾N NGHá»Š ÄIá»€U TRá»Š:
{result.get('treatment_recommendation', 'Cáº§n tham kháº£o thÃªm Ã½ kiáº¿n chuyÃªn gia')}

ğŸ“… Káº¾ HOáº CH THEO DÃ•I:
{result.get('follow_up_plan', 'Theo dÃµi Ä‘á»‹nh ká»³ 3-6 thÃ¡ng')}

âš ï¸ Yáº¾U Tá» NGUY CÆ :
{result.get('risk_factors', 'Cáº§n theo dÃµi cháº·t cháº½ cÃ¡c chá»‰ sá»‘ PSA vÃ  triá»‡u chá»©ng lÃ¢m sÃ ng')}
                """.strip(),
                'assessment_date': datetime.utcnow()
            }
            
            return processed_result
            
        else:
            raise ValueError("KhÃ´ng nháº­n Ä‘Æ°á»£c pháº£n há»“i tá»« AI")
            
    except json.JSONDecodeError as e:
        logging.error(f"JSON decode error in AI assessment: {e}")
        return {
            'risk_score': 'TRUNG BÃŒNH',
            'assessment_summary': 'Lá»—i phÃ¢n tÃ­ch dá»¯ liá»‡u. Vui lÃ²ng tham kháº£o Ã½ kiáº¿n bÃ¡c sÄ© chuyÃªn khoa.',
            'assessment_date': datetime.utcnow()
        }
    except Exception as e:
        logging.error(f"Error in AI risk assessment: {e}")
        return {
            'risk_score': 'TRUNG BÃŒNH', 
            'assessment_summary': 'KhÃ´ng thá»ƒ thá»±c hiá»‡n Ä‘Ã¡nh giÃ¡ tá»± Ä‘á»™ng. Vui lÃ²ng tham kháº£o Ã½ kiáº¿n bÃ¡c sÄ© chuyÃªn khoa.',
            'assessment_date': datetime.utcnow()
        }

def analyze_pathology_image(image_path):
    """
    PhÃ¢n tÃ­ch hÃ¬nh áº£nh giáº£i pháº«u bá»‡nh báº±ng AI Gemini
    Analyze pathology image using AI Gemini
    """
    try:
        with open(image_path, "rb") as f:
            image_bytes = f.read()
            
        prompt = """
        Báº¡n lÃ  má»™t chuyÃªn gia giáº£i pháº«u bá»‡nh chuyÃªn vá» ung thÆ° tuyáº¿n tiá»n liá»‡t. 
        HÃ£y phÃ¢n tÃ­ch hÃ¬nh áº£nh giáº£i pháº«u bá»‡nh nÃ y vÃ  mÃ´ táº£:
        
        1. Äáº·c Ä‘iá»ƒm mÃ´ há»c quan sÃ¡t Ä‘Æ°á»£c
        2. Má»©c Ä‘á»™ biá»‡t hÃ³a táº¿ bÃ o
        3. Dáº¥u hiá»‡u xÃ¢m láº¥n máº¡ch mÃ¡u hoáº·c tháº§n kinh
        4. Äá» xuáº¥t Ä‘iá»ƒm Gleason (náº¿u cÃ³ thá»ƒ)
        5. CÃ¡c phÃ¡t hiá»‡n báº¥t thÆ°á»ng khÃ¡c
        
        Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, chuyÃªn nghiá»‡p vÃ  chi tiáº¿t.
        """
        
        response = client.models.generate_content(
            model="gemini-2.5-pro",
            contents=[
                types.Part.from_bytes(
                    data=image_bytes,
                    mime_type="image/jpeg",
                ),
                prompt
            ],
        )
        
        return response.text if response.text else "KhÃ´ng thá»ƒ phÃ¢n tÃ­ch hÃ¬nh áº£nh."
        
    except Exception as e:
        logging.error(f"Error analyzing pathology image: {e}")
        return "Lá»—i phÃ¢n tÃ­ch hÃ¬nh áº£nh. Vui lÃ²ng kiá»ƒm tra láº¡i file hÃ¬nh áº£nh."